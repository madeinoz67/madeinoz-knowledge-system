# API Contract: Cache Response Metadata

**Feature**: 006-gemini-prompt-caching
**Date**: 2026-01-27
**Status**: Phase 1 Complete
**Contract Type**: Response Enhancement

---

## Overview

This contract defines the cache metrics structure embedded in MCP tool responses when using Gemini models with prompt caching enabled. The `cache_metrics` field provides transparency into caching effectiveness and cost savings for each API call.

---

## Response Format

### Enhanced MCP Response Schema

All MCP tool responses (`add_memory`, `search_nodes`, `search_memory_facts`, etc.) include an optional `cache_metrics` object when:
1. The request used a Gemini model, AND
2. Prompt caching is enabled (`MADEINOZ_KNOWLEDGE_PROMPT_CACHE_ENABLED=true`)

```typescript
interface McpToolResponse {
  // Existing response fields (tool-specific)
  result: unknown;

  // NEW: Cache metrics (optional, Gemini only)
  cache_metrics?: CacheMetrics;
}
```

### CacheMetrics Schema

```typescript
interface CacheMetrics {
  /**
   * Whether any tokens were served from Gemini's cache.
   * True if cached_tokens > 0.
   */
  cache_hit: boolean;

  /**
   * Number of input tokens retrieved from cache.
   * These tokens are billed at the discounted cached rate.
   * Range: 0 to prompt_tokens
   */
  cached_tokens: number;

  /**
   * Total input tokens in the request.
   * Includes both cached and uncached tokens.
   */
  prompt_tokens: number;

  /**
   * Output tokens generated by the model.
   * Not affected by caching (output is always fresh).
   */
  completion_tokens: number;

  /**
   * Semantic alias for cached_tokens.
   * Indicates how many tokens were "saved" from re-processing.
   */
  tokens_saved: number;

  /**
   * Hypothetical cost if caching was not used (USD).
   * Calculated as: (prompt_tokens * input_rate + completion_tokens * output_rate)
   * Precision: 8 decimal places
   */
  cost_without_cache: number;

  /**
   * Actual API cost after cache discount (USD).
   * Calculated as: (uncached_tokens * input_rate + cached_tokens * cached_rate + completion_tokens * output_rate)
   * Precision: 8 decimal places
   */
  actual_cost: number;

  /**
   * Monetary savings from caching (USD).
   * Calculated as: cost_without_cache - actual_cost
   * Always >= 0
   */
  cost_saved: number;

  /**
   * Percentage reduction in cost.
   * Calculated as: (cost_saved / cost_without_cache) * 100
   * Range: 0.0 to 100.0
   */
  savings_percent: number;

  /**
   * Gemini model identifier used for pricing.
   * Examples: "gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"
   */
  model: string;
}
```

### JSON Schema (Formal)

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "CacheMetrics",
  "type": "object",
  "required": [
    "cache_hit",
    "cached_tokens",
    "prompt_tokens",
    "completion_tokens",
    "tokens_saved",
    "cost_without_cache",
    "actual_cost",
    "cost_saved",
    "savings_percent",
    "model"
  ],
  "properties": {
    "cache_hit": {
      "type": "boolean",
      "description": "Whether any tokens were served from cache"
    },
    "cached_tokens": {
      "type": "integer",
      "minimum": 0,
      "description": "Count of tokens retrieved from cache"
    },
    "prompt_tokens": {
      "type": "integer",
      "minimum": 1,
      "description": "Total input tokens in the request"
    },
    "completion_tokens": {
      "type": "integer",
      "minimum": 0,
      "description": "Output tokens generated by the model"
    },
    "tokens_saved": {
      "type": "integer",
      "minimum": 0,
      "description": "Same as cached_tokens (semantic alias)"
    },
    "cost_without_cache": {
      "type": "number",
      "minimum": 0,
      "description": "Hypothetical cost without caching (USD)"
    },
    "actual_cost": {
      "type": "number",
      "minimum": 0,
      "description": "Actual API cost (USD)"
    },
    "cost_saved": {
      "type": "number",
      "minimum": 0,
      "description": "Monetary savings (USD)"
    },
    "savings_percent": {
      "type": "number",
      "minimum": 0,
      "maximum": 100,
      "description": "Percentage cost reduction"
    },
    "model": {
      "type": "string",
      "pattern": "^gemini-[0-9]\\.[0-9]-(flash|pro)$",
      "description": "Gemini model identifier"
    }
  },
  "additionalProperties": false
}
```

---

## Examples

### Cache Hit Response

Request resulted in cache hit (second request with same system prompt):

```json
{
  "result": {
    "nodes": [
      {"name": "Entity1", "type": "Person"},
      {"name": "Entity2", "type": "Organization"}
    ]
  },
  "cache_metrics": {
    "cache_hit": true,
    "cached_tokens": 1523,
    "prompt_tokens": 2048,
    "completion_tokens": 342,
    "tokens_saved": 1523,
    "cost_without_cache": 0.00147050,
    "actual_cost": 0.00106325,
    "cost_saved": 0.00040725,
    "savings_percent": 27.69,
    "model": "gemini-2.5-flash"
  }
}
```

### Cache Miss Response

First request or prompt changed (no cache hit):

```json
{
  "result": {
    "episode_id": "ep_abc123",
    "entities_extracted": 5
  },
  "cache_metrics": {
    "cache_hit": false,
    "cached_tokens": 0,
    "prompt_tokens": 2048,
    "completion_tokens": 512,
    "tokens_saved": 0,
    "cost_without_cache": 0.00189400,
    "actual_cost": 0.00189400,
    "cost_saved": 0.00000000,
    "savings_percent": 0.0,
    "model": "gemini-2.5-flash"
  }
}
```

### High Savings Response (Long Context)

Request with large cached context achieving significant savings:

```json
{
  "result": {
    "facts": [
      {"subject": "Alice", "predicate": "works_at", "object": "TechCorp"}
    ]
  },
  "cache_metrics": {
    "cache_hit": true,
    "cached_tokens": 15000,
    "prompt_tokens": 16500,
    "completion_tokens": 200,
    "tokens_saved": 15000,
    "cost_without_cache": 0.00695000,
    "actual_cost": 0.00149500,
    "cost_saved": 0.00545500,
    "savings_percent": 78.49,
    "model": "gemini-2.5-flash"
  }
}
```

---

## Error Cases

### Caching Disabled

When caching is disabled via environment variable, `cache_metrics` is omitted entirely:

```json
{
  "result": {
    "nodes": []
  }
}
```

### Non-Gemini Model

When using OpenAI, Anthropic, or other providers, `cache_metrics` is omitted:

```json
{
  "result": {
    "episode_id": "ep_xyz789"
  }
}
```

### Metrics Retrieval Failed

If metrics cannot be extracted from Gemini response (API issue), response includes partial metrics with error flag:

```json
{
  "result": {
    "nodes": [{"name": "Entity1"}]
  },
  "cache_metrics": {
    "cache_hit": false,
    "cached_tokens": 0,
    "prompt_tokens": 0,
    "completion_tokens": 0,
    "tokens_saved": 0,
    "cost_without_cache": 0,
    "actual_cost": 0,
    "cost_saved": 0,
    "savings_percent": 0,
    "model": "gemini-2.5-flash",
    "_error": "Failed to retrieve usage_metadata from Gemini response"
  }
}
```

---

## Cost Calculation Reference

### Formula

```
uncached_tokens = prompt_tokens - cached_tokens

cost_without_cache = (prompt_tokens * input_rate + completion_tokens * output_rate) / 1,000,000

actual_cost = (uncached_tokens * input_rate + cached_tokens * cached_rate + completion_tokens * output_rate) / 1,000,000

cost_saved = cost_without_cache - actual_cost

savings_percent = (cost_saved / cost_without_cache) * 100  [if cost_without_cache > 0, else 0]
```

### Pricing Rates (January 2026)

| Model | Input Rate | Cached Rate | Output Rate | Cache Discount |
|-------|------------|-------------|-------------|----------------|
| gemini-2.5-flash | $0.30/1M | $0.03/1M | $2.50/1M | 90% |
| gemini-2.5-pro | $1.25/1M | $0.125/1M | $10.00/1M | 90% |
| gemini-2.0-flash | $0.10/1M | $0.01/1M | $0.40/1M | 90% |

---

## Validation Invariants

The following must always be true for a valid `cache_metrics` object:

1. `cached_tokens <= prompt_tokens`
2. `tokens_saved == cached_tokens`
3. `cost_saved >= 0`
4. `actual_cost <= cost_without_cache`
5. `savings_percent >= 0 && savings_percent <= 100`
6. `cache_hit == (cached_tokens > 0)`
7. `cost_saved == cost_without_cache - actual_cost` (within floating-point tolerance)

---

## Client Integration Notes

### Accessing Cache Metrics

```typescript
// TypeScript example
const response = await mcpClient.callTool('search_nodes', { query: 'Alice' });

if (response.cache_metrics) {
  console.log(`Cache hit: ${response.cache_metrics.cache_hit}`);
  console.log(`Saved: $${response.cache_metrics.cost_saved.toFixed(6)}`);
  console.log(`Savings: ${response.cache_metrics.savings_percent.toFixed(1)}%`);
}
```

### Aggregating Session Metrics

```typescript
// Accumulate metrics across multiple requests
let sessionMetrics = {
  totalRequests: 0,
  totalCacheHits: 0,
  totalCostSaved: 0,
  totalActualCost: 0,
};

function updateSessionMetrics(cacheMetrics: CacheMetrics) {
  sessionMetrics.totalRequests++;
  if (cacheMetrics.cache_hit) sessionMetrics.totalCacheHits++;
  sessionMetrics.totalCostSaved += cacheMetrics.cost_saved;
  sessionMetrics.totalActualCost += cacheMetrics.actual_cost;
}

// Calculate session hit rate
const hitRate = (sessionMetrics.totalCacheHits / sessionMetrics.totalRequests) * 100;
```

---

## Backward Compatibility

- **Existing clients**: Will ignore the new `cache_metrics` field (additive change)
- **Schema validation**: Clients using strict JSON schema validation should allow `additionalProperties`
- **Caching disabled**: Response format unchanged when `MADEINOZ_KNOWLEDGE_PROMPT_CACHE_ENABLED=false`
