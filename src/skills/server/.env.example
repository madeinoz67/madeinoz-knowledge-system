# Madeinoz Knowledge System - Environment Configuration
# Copy this file to your .env location (see INSTALL.md for location)
#
# This file is for direct container usage (unprefixed variables)
# The start.sh script generates this from MADEINOZ_KNOWLEDGE_* prefixed variables

# ============================================================================
# REQUIRED: API Keys
# ============================================================================

# Primary API Key (for OpenRouter, OpenAI, or compatible provider)
# Get your key from: https://openrouter.ai/keys
OPENAI_API_KEY=sk-your-api-key-here

# Optional: Alternative provider API keys
# ANTHROPIC_API_KEY=your-anthropic-key
# GOOGLE_API_KEY=your-google-key
# GROQ_API_KEY=your-groq-key
# VOYAGE_API_KEY=your-voyage-key

# ============================================================================
# LLM Configuration
# ============================================================================

# LLM Provider: openai, anthropic, gemini, groq
LLM_PROVIDER=openai

# Model to use (examples)
# - OpenRouter: openai/gpt-4o-mini, google/gemini-2.0-flash-001, anthropic/claude-3.5-haiku
# - OpenAI: gpt-4o-mini, gpt-4o
# - Direct provider: gemini-2.0-flash-001, claude-3.5-sonnet, llama-3.3-70b
MODEL_NAME=openai/gpt-4o-mini

# API Endpoint (for OpenRouter, Together AI, or custom OpenAI-compatible API)
# Default for OpenRouter:
OPENAI_BASE_URL=https://openrouter.ai/api/v1
# For OpenAI directly:
# OPENAI_BASE_URL=https://api.openai.com/v1
# For Ollama (local LLM):
# OPENAI_BASE_URL=http://host.docker.internal:11434/v1

# ============================================================================
# Embedder Configuration
# ============================================================================

# Embedder Provider: openai, ollama, gemini, voyage
EMBEDDER_PROVIDER=ollama

# Embedding Model
# - Ollama: mxbai-embed-large (1024 dims), nomic-embed-text (768 dims)
# - OpenAI: text-embedding-3-small (1536 dims), text-embedding-ada-002 (1536 dims)
EMBEDDER_MODEL=mxbai-embed-large

# Embedding Dimensions (MUST match your model!)
# mxbai-embed-large: 1024
# nomic-embed-text: 768
# text-embedding-3-small: 1536
EMBEDDER_DIMENSIONS=1024

# Ollama Endpoint (for local embedder)
# Docker/Podman: http://host.containers.internal:11434/v1
# Same machine: http://localhost:11434/v1
# Remote: http://YOUR_IP:11434/v1
OLLAMA_BASE_URL=http://host.containers.internal:11434/v1

# ============================================================================
# Database Configuration
# ============================================================================

# Database Type: neo4j or falkordb
DATABASE_TYPE=neo4j

# Neo4j Configuration (when DATABASE_TYPE=neo4j)
NEO4J_URI=bolt://madeinoz-knowledge-neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=madeinozknowledge
NEO4J_DATABASE=neo4j

# FalkorDB Configuration (when DATABASE_TYPE=falkordb)
FALKORDB_HOST=madeinoz-knowledge-falkordb
FALKORDB_PORT=6379
FALKORDB_PASSWORD=

# ============================================================================
# Knowledge Graph Configuration
# ============================================================================

# Group ID for isolating knowledge graphs
GROUP_ID=main

# Performance
SEMAPHORE_LIMIT=10

# Telemetry
GRAPHITI_TELEMETRY_ENABLED=false
NEO4J_TELEMETRY_ENABLED=false

# Search All Groups (Neo4j only)
# When true, searches all groups when no group_ids specified
# SECURITY: Default is false for least privilege (data isolation between groups)
GRAPHITI_SEARCH_ALL_GROUPS=${GRAPHITI_SEARCH_ALL_GROUPS:-false}

# ============================================================================
# REFERENCE: Working Model Combinations
# ============================================================================
#
# OpenRouter + Local Ollama Embeddings (RECOMMENDED):
#   LLM_PROVIDER=openai
#   MODEL_NAME=openai/gpt-4o-mini
#   OPENAI_BASE_URL=https://openrouter.ai/api/v1
#   EMBEDDER_PROVIDER=ollama
#   EMBEDDER_MODEL=mxbai-embed-large
#   OLLAMA_BASE_URL=http://host.containers.internal:11434/v1
#
# All OpenRouter (Simple, No Local Setup):
#   LLM_PROVIDER=openai
#   MODEL_NAME=openai/gpt-4o-mini
#   OPENAI_BASE_URL=https://openrouter.ai/api/v1
#   EMBEDDER_PROVIDER=openai
#   EMBEDDER_MODEL=text-embedding-3-small
#
# All Local Ollama (FREE, No API Keys):
#   LLM_PROVIDER=openai
#   MODEL_NAME=llama3.2
#   OPENAI_BASE_URL=http://host.docker.internal:11434/v1
#   EMBEDDER_PROVIDER=ollama
#   EMBEDDER_MODEL=mxbai-embed-large
#   OLLAMA_BASE_URL=http://host.docker.internal:11434/v1
#   OPENAI_API_KEY=ollama  # Dummy key for Ollama
