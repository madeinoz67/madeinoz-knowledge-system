# Docker Compose configuration for Madeinoz Knowledge System
# Uses a shared public network for both services

name: madeinoz-knowledge-system
#
# Services:
#   - falkordb: Graph database backend
#   - graphiti-mcp: MCP server (exposed to host)
#
# Madeinoz Patch APPLIED:
#   factories.py - Enables Ollama/custom endpoint support by using
#   OpenAIGenericClient (which uses /v1/chat/completions) instead of
#   OpenAIClient (which uses /v1/responses that Ollama doesn't support).
#   This fixes upstream GitHub issue #1116.
#
# Usage from pack directory:
#   1. Copy src/config/.env.example to src/config/.env and configure your API keys
#   2. Run: docker compose -f src/server/docker-compose.yml up -d
#   3. MCP server uses HTTP transport at: http://localhost:8000/mcp
#   4. Access FalkorDB web UI at: http://localhost:3000

networks:
  madeinoz-knowledge-net:
    driver: bridge

volumes:
  falkordb-data:
    driver: local

services:
  # FalkorDB Graph Database
  # On public network, web UI exposed to host
  falkordb:
    image: falkordb/falkordb:latest
    container_name: madeinoz-knowledge-falkordb
    restart: unless-stopped
    networks:
      - madeinoz-knowledge-net
    volumes:
      - falkordb-data:/data
    environment:
      - FALKORDB_PASSWORD=${FALKORDB_PASSWORD:-}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # Graphiti MCP Server
  # Exposed to host on ports 8000 (MCP) and 3000 (FalkorDB UI)
  graphiti-mcp:
    image: falkordb/graphiti-knowledge-graph-mcp:latest
    container_name: madeinoz-knowledge-graph-mcp
    restart: unless-stopped
    networks:
      - madeinoz-knowledge-net
    ports:
      - "8000:8000"  # MCP HTTP endpoint
      - "3000:3000"  # FalkorDB web UI proxy
    environment:
      # Database Configuration - connect to FalkorDB service
      - DATABASE_TYPE=falkordb
      - FALKORDB_HOST=falkordb
      - FALKORDB_PORT=6379
      # All other config loaded from env_file
    volumes:
      # Madeinoz Patch: Ollama/custom endpoint support (fixes GitHub issue #1116)
      - ./patches/factories.py:/app/mcp/src/services/factories.py:ro
    env_file:
      # Reads directly from PAI .env (source of truth)
      # Uses PAI_DIR if set, otherwise defaults to ~/.claude
      - ${PAI_DIR:-~/.claude}/.env
    depends_on:
      falkordb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-sf", "--max-time", "5", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
